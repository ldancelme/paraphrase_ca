{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paraphrase ça !\n",
    "\n",
    "Remplace les mots d'une phrase par des synonymes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A faire tourner une seule fois\n",
    "!pip install spacy requests\n",
    "!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import fr_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse de la phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Galaxie\n",
      "\n",
      "Token\t\tLemma\t\tStopword\tDEP\t\tPOS\n",
      "----------------------------------------------------------------------\n",
      "Galaxie\t\tgalaxie\t\tFalse\t\tROOT\t\tNOUN\n"
     ]
    }
   ],
   "source": [
    "# nlp = spacy.load(\"fr_core_news_sm\")\n",
    "nlp = fr_core_news_sm.load()\n",
    " \n",
    "sentence = input()\n",
    "doc = nlp(sentence)\n",
    "\n",
    "# Text Preprocessing | Lemmatization\n",
    "print(\"\\n\" + f\"Token\\t\\tLemma\\t\\tStopword\\tDEP\\t\\tPOS\".format('Token', 'Lemma', 'Stopword'))\n",
    "print(\"-\"*70)\n",
    "for token in doc:\n",
    "    print(f\"{str(token)}\\t\\t{token.lemma_}\\t\\t{token.is_stop}\\t\\t{token.dep_}\\t\\t{token.pos_}\")\n",
    "\n",
    "pos_tochange = ['PRON', 'VERB', 'NOUN','ADJ','ADV']    \n",
    "sentence_dict = {idx:str(token) for (idx,token) in enumerate(doc)}\n",
    "to_synos = {idx:str(token) for (idx,token) in enumerate(doc) if token.pos_ in pos_tochange}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web Scrapping\n",
    "Extraction des synonymes depuis le site [Synonymo](http://www.synonymo.fr/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_synos(word):\n",
    "    \n",
    "    url = 'http://www.synonymo.fr/syno/' + str(word)\n",
    "    get = requests.get(url)\n",
    "    get.encoding = get.apparent_encoding\n",
    "    html = get.text\n",
    "    \n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "                         # features='lxml')\n",
    "    raw_text = soup.prettify()\n",
    "    \n",
    "    ul = soup.find('ul', {'class':'synos'})\n",
    "    \n",
    "    try : \n",
    "        first = ul.findAll('a')\n",
    "        synos = [i.next for i in first]\n",
    "        syno = random.choice(synos)\n",
    "        return syno\n",
    "    \n",
    "    except AttributeError:\n",
    "        return word  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction de la phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "IDX\tWORD\t\tSYNONYM\n",
      "----------------------------------\n",
      "0\tGalaxie\t\tnébuleuse\n",
      "\n",
      "\n",
      "\"Galaxie\" devient \"nébuleuse\"\n"
     ]
    }
   ],
   "source": [
    "synos = [extract_synos(x) for x in to_synos.values()]\n",
    "synos_dict = {}\n",
    "for idx, val in zip(to_synos.keys(), synos):\n",
    "    d = {idx: val}\n",
    "    synos_dict.update(d)\n",
    "    \n",
    "print(\"\\n\" + f\"IDX\\tWORD\\t\\tSYNONYM\")\n",
    "print(\"-\"*34)\n",
    "\n",
    "for i, w, s in zip(to_synos.keys(), to_synos.values(), synos):\n",
    "    print(f\"{i}\\t{w}\\t\\t{s}\")\n",
    "    \n",
    "paraphrase_dict = sentence_dict.copy()\n",
    "for i in synos_dict.keys():\n",
    "    paraphrase_dict[i] = synos_dict[i] \n",
    "\n",
    "new_sentence = \" \".join(paraphrase_dict.values())\n",
    "print('\\n\\n\"{}\" devient \"{}\"'.format(sentence, new_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
